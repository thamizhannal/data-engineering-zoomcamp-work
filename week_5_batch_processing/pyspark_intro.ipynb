{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ae6ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84fc86e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/07/04 14:03:16 WARN Utils: Your hostname, DESKTOP-KMM8QC4 resolves to a loopback address: 127.0.1.1; using 172.24.131.74 instead (on interface eth0)\n",
      "22/07/04 14:03:16 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/thamizh/apps/spark-3.0.3-bin-hadoop3.2/jars/spark-unsafe_2.12-3.0.3.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "22/07/04 14:03:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/07/04 14:03:20 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4226614f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-07-04 14:08:40--  https://s3.amazonaws.com/nyc-tlc/csv_backup/fhvhv_tripdata_2021-01.csv\n",
      "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.217.142.200\n",
      "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.217.142.200|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 752335705 (717M) [text/csv]\n",
      "Saving to: ‘fhvhv_tripdata_2021-01.csv’\n",
      "\n",
      "fhvhv_tripdata_2021 100%[===================>] 717.48M  1.85MB/s    in 12m 17s \n",
      "\n",
      "2022-07-04 14:20:58 (997 KB/s) - ‘fhvhv_tripdata_2021-01.csv’ saved [752335705/752335705]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !wget --no-check-certificate https://nyc-tlc.s3.amazoneaws.com/trip+data/fhvhv_tripdata_2021-01.csv\n",
    "!wget https://s3.amazonaws.com/nyc-tlc/csv_backup/fhvhv_tripdata_2021-01.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9f968481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fhvhv_tripdata_2021-01.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls fhvhv_tripdata_2021-01.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a91858ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "718M\tfhvhv_tripdata_2021-01.csv\r\n"
     ]
    }
   ],
   "source": [
    "!du -sh  fhvhv_tripdata_2021-01.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d16ed08",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv('fhvhv_tripdata_2021-01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91bf4d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|hvfhs_license_num|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|           HV0003|              B02682|2021-01-01 00:33:44|2021-01-01 00:49:07|         230|         166|   null|\n",
      "|           HV0003|              B02682|2021-01-01 00:55:19|2021-01-01 01:18:21|         152|         167|   null|\n",
      "|           HV0003|              B02764|2021-01-01 00:23:56|2021-01-01 00:38:05|         233|         142|   null|\n",
      "|           HV0003|              B02764|2021-01-01 00:42:51|2021-01-01 00:45:50|         142|         143|   null|\n",
      "|           HV0003|              B02764|2021-01-01 00:48:14|2021-01-01 01:08:42|         143|          78|   null|\n",
      "|           HV0005|              B02510|2021-01-01 00:06:59|2021-01-01 00:43:01|          88|          42|   null|\n",
      "|           HV0005|              B02510|2021-01-01 00:50:00|2021-01-01 01:04:57|          42|         151|   null|\n",
      "|           HV0003|              B02764|2021-01-01 00:14:30|2021-01-01 00:50:27|          71|         226|   null|\n",
      "|           HV0003|              B02875|2021-01-01 00:22:54|2021-01-01 00:30:20|         112|         255|   null|\n",
      "|           HV0003|              B02875|2021-01-01 00:40:12|2021-01-01 00:53:31|         255|         232|   null|\n",
      "|           HV0003|              B02875|2021-01-01 00:56:45|2021-01-01 01:17:42|         232|         198|   null|\n",
      "|           HV0003|              B02835|2021-01-01 00:29:04|2021-01-01 00:36:27|         113|          48|   null|\n",
      "|           HV0003|              B02835|2021-01-01 00:48:56|2021-01-01 00:59:12|         239|          75|   null|\n",
      "|           HV0004|              B02800|2021-01-01 00:15:24|2021-01-01 00:38:31|         181|         237|   null|\n",
      "|           HV0004|              B02800|2021-01-01 00:45:00|2021-01-01 01:06:45|         236|          68|   null|\n",
      "|           HV0003|              B02682|2021-01-01 00:11:53|2021-01-01 00:18:06|         256|         148|   null|\n",
      "|           HV0003|              B02682|2021-01-01 00:28:31|2021-01-01 00:41:40|          79|          80|   null|\n",
      "|           HV0003|              B02682|2021-01-01 00:50:49|2021-01-01 00:55:59|          17|         217|   null|\n",
      "|           HV0005|              B02510|2021-01-01 00:08:40|2021-01-01 00:39:39|          62|          29|   null|\n",
      "|           HV0003|              B02836|2021-01-01 00:53:48|2021-01-01 01:11:40|          22|          22|   null|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17a408bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(hvfhs_license_num='HV0003', dispatching_base_num='B02682', pickup_datetime='2021-01-01 00:33:44', dropoff_datetime='2021-01-01 00:49:07', PULocationID='230', DOLocationID='166', SR_Flag=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ceb0026a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(hvfhs_license_num,StringType,true),StructField(dispatching_base_num,StringType,true),StructField(pickup_datetime,StringType,true),StructField(dropoff_datetime,StringType,true),StructField(PULocationID,StringType,true),StructField(DOLocationID,StringType,true),StructField(SR_Flag,StringType,true)))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To display the spark data types for fields\n",
    "df.schema\n",
    "# Here pickup_datetime & dropoff_datetime fields were string type, needs to be converted into datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebe3ee9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -101 fhvhv_tripdata_2021-01.csv > head.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c65f6a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hvfhs_license_num,dispatching_base_num,pickup_datetime,dropoff_datetime,PULocationID,DOLocationID,SR_Flag\r",
      "\r\n",
      "HV0003,B02682,2021-01-01 00:33:44,2021-01-01 00:49:07,230,166,\r",
      "\r\n",
      "HV0003,B02682,2021-01-01 00:55:19,2021-01-01 01:18:21,152,167,\r",
      "\r\n",
      "HV0003,B02764,2021-01-01 00:23:56,2021-01-01 00:38:05,233,142,\r",
      "\r\n",
      "HV0003,B02764,2021-01-01 00:42:51,2021-01-01 00:45:50,142,143,\r",
      "\r\n",
      "HV0003,B02764,2021-01-01 00:48:14,2021-01-01 01:08:42,143,78,\r",
      "\r\n",
      "HV0005,B02510,2021-01-01 00:06:59,2021-01-01 00:43:01,88,42,\r",
      "\r\n",
      "HV0005,B02510,2021-01-01 00:50:00,2021-01-01 01:04:57,42,151,\r",
      "\r\n",
      "HV0003,B02764,2021-01-01 00:14:30,2021-01-01 00:50:27,71,226,\r",
      "\r\n",
      "HV0003,B02875,2021-01-01 00:22:54,2021-01-01 00:30:20,112,255,\r",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!head head.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41580d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "080ec269",
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_df = pd.read_csv('head.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "250a3ac4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hvfhs_license_num        object\n",
       "dispatching_base_num     object\n",
       "pickup_datetime          object\n",
       "dropoff_datetime         object\n",
       "PULocationID              int64\n",
       "DOLocationID              int64\n",
       "SR_Flag                 float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas_df.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10574711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 3:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|hvfhs_license_num|dispatching_base_num|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|SR_Flag|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "|           HV0003|              B02682|2021-01-01 00:33:44|2021-01-01 00:49:07|         230|         166|    NaN|\n",
      "|           HV0003|              B02682|2021-01-01 00:55:19|2021-01-01 01:18:21|         152|         167|    NaN|\n",
      "|           HV0003|              B02764|2021-01-01 00:23:56|2021-01-01 00:38:05|         233|         142|    NaN|\n",
      "|           HV0003|              B02764|2021-01-01 00:42:51|2021-01-01 00:45:50|         142|         143|    NaN|\n",
      "|           HV0003|              B02764|2021-01-01 00:48:14|2021-01-01 01:08:42|         143|          78|    NaN|\n",
      "|           HV0005|              B02510|2021-01-01 00:06:59|2021-01-01 00:43:01|          88|          42|    NaN|\n",
      "|           HV0005|              B02510|2021-01-01 00:50:00|2021-01-01 01:04:57|          42|         151|    NaN|\n",
      "|           HV0003|              B02764|2021-01-01 00:14:30|2021-01-01 00:50:27|          71|         226|    NaN|\n",
      "|           HV0003|              B02875|2021-01-01 00:22:54|2021-01-01 00:30:20|         112|         255|    NaN|\n",
      "|           HV0003|              B02875|2021-01-01 00:40:12|2021-01-01 00:53:31|         255|         232|    NaN|\n",
      "|           HV0003|              B02875|2021-01-01 00:56:45|2021-01-01 01:17:42|         232|         198|    NaN|\n",
      "|           HV0003|              B02835|2021-01-01 00:29:04|2021-01-01 00:36:27|         113|          48|    NaN|\n",
      "|           HV0003|              B02835|2021-01-01 00:48:56|2021-01-01 00:59:12|         239|          75|    NaN|\n",
      "|           HV0004|              B02800|2021-01-01 00:15:24|2021-01-01 00:38:31|         181|         237|    NaN|\n",
      "|           HV0004|              B02800|2021-01-01 00:45:00|2021-01-01 01:06:45|         236|          68|    NaN|\n",
      "|           HV0003|              B02682|2021-01-01 00:11:53|2021-01-01 00:18:06|         256|         148|    NaN|\n",
      "|           HV0003|              B02682|2021-01-01 00:28:31|2021-01-01 00:41:40|          79|          80|    NaN|\n",
      "|           HV0003|              B02682|2021-01-01 00:50:49|2021-01-01 00:55:59|          17|         217|    NaN|\n",
      "|           HV0005|              B02510|2021-01-01 00:08:40|2021-01-01 00:39:39|          62|          29|    NaN|\n",
      "|           HV0003|              B02836|2021-01-01 00:53:48|2021-01-01 01:11:40|          22|          22|    NaN|\n",
      "+-----------------+--------------------+-------------------+-------------------+------------+------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame(pandas_df).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ae749c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType(List(StructField(hvfhs_license_num,StringType,true),StructField(dispatching_base_num,StringType,true),StructField(pickup_datetime,StringType,true),StructField(dropoff_datetime,StringType,true),StructField(PULocationID,LongType,true),StructField(DOLocationID,LongType,true),StructField(SR_Flag,DoubleType,true)))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.createDataFrame(pandas_df).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63567c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "### PULocationID and DOLocationID were stored as LongType that consumes 8bytes in memory, \n",
    "### this can be modified to int type(4 bytes) for better mem. utilization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "025736ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## It is conveient to descibe custom schema types according to the operations going to be performed on this data set\n",
    "## Spark is implemented in scala lang. the types in the schema should be defined as per in Scala lang definition not in python specific\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c5a7f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StringType, TimestampType, IntegerType, StructField,StructType\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9caceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = StructType ([\n",
    "    StructField('hvfhs_license_num',StringType(),True),\n",
    "    StructField('dispatching_base_num',StringType(),True),\n",
    "    StructField('pickup_datetime',TimestampType(),True),\n",
    "    StructField('dropoff_datetime',TimestampType(),True),\n",
    "    StructField('PULocationID',IntegerType(),True),\n",
    "    StructField('DOLocationID',IntegerType(),True),\n",
    "    StructField('SR_Flag',StringType(),True)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "163f9e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply schema to spark data frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "64ef2eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .csv('fhvhv_tripdata_2021-01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fe5e786a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(hvfhs_license_num='HV0003', dispatching_base_num='B02682', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 33, 44), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 49, 7), PULocationID=230, DOLocationID=166, SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02682', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 55, 19), dropoff_datetime=datetime.datetime(2021, 1, 1, 1, 18, 21), PULocationID=152, DOLocationID=167, SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 23, 56), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 38, 5), PULocationID=233, DOLocationID=142, SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 42, 51), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 45, 50), PULocationID=142, DOLocationID=143, SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 48, 14), dropoff_datetime=datetime.datetime(2021, 1, 1, 1, 8, 42), PULocationID=143, DOLocationID=78, SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0005', dispatching_base_num='B02510', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 6, 59), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 43, 1), PULocationID=88, DOLocationID=42, SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0005', dispatching_base_num='B02510', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 50), dropoff_datetime=datetime.datetime(2021, 1, 1, 1, 4, 57), PULocationID=42, DOLocationID=151, SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02764', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 14, 30), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 50, 27), PULocationID=71, DOLocationID=226, SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02875', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 22, 54), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 30, 20), PULocationID=112, DOLocationID=255, SR_Flag=None),\n",
       " Row(hvfhs_license_num='HV0003', dispatching_base_num='B02875', pickup_datetime=datetime.datetime(2021, 1, 1, 0, 40, 12), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 53, 31), PULocationID=255, DOLocationID=232, SR_Flag=None)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/07/04 15:39:57 WARN HeartbeatReceiver: Removing executor driver with no recent heartbeats: 2798692 ms exceeds timeout 120000 ms\n",
      "22/07/04 15:39:57 WARN SparkContext: Killing executors is not supported by current scheduler.\n"
     ]
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "650f3288",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cb450f16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.parquet('fhvhv/2021/01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bd650d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_SUCCESS\r\n",
      "part-00000-e4c9e549-9fd3-4a97-b8b1-2cc71872198f-c000.snappy.parquet\r\n",
      "part-00001-e4c9e549-9fd3-4a97-b8b1-2cc71872198f-c000.snappy.parquet\r\n",
      "part-00002-e4c9e549-9fd3-4a97-b8b1-2cc71872198f-c000.snappy.parquet\r\n",
      "part-00003-e4c9e549-9fd3-4a97-b8b1-2cc71872198f-c000.snappy.parquet\r\n",
      "part-00004-e4c9e549-9fd3-4a97-b8b1-2cc71872198f-c000.snappy.parquet\r\n",
      "part-00005-e4c9e549-9fd3-4a97-b8b1-2cc71872198f-c000.snappy.parquet\r\n",
      "part-00006-e4c9e549-9fd3-4a97-b8b1-2cc71872198f-c000.snappy.parquet\r\n",
      "part-00007-e4c9e549-9fd3-4a97-b8b1-2cc71872198f-c000.snappy.parquet\r\n",
      "part-00008-e4c9e549-9fd3-4a97-b8b1-2cc71872198f-c000.snappy.parquet\r\n",
      "part-00009-e4c9e549-9fd3-4a97-b8b1-2cc71872198f-c000.snappy.parquet\r\n",
      "part-00010-e4c9e549-9fd3-4a97-b8b1-2cc71872198f-c000.snappy.parquet\r\n",
      "part-00011-e4c9e549-9fd3-4a97-b8b1-2cc71872198f-c000.snappy.parquet\r\n",
      "part-00012-e4c9e549-9fd3-4a97-b8b1-2cc71872198f-c000.snappy.parquet\r\n",
      "part-00013-e4c9e549-9fd3-4a97-b8b1-2cc71872198f-c000.snappy.parquet\r\n",
      "part-00014-e4c9e549-9fd3-4a97-b8b1-2cc71872198f-c000.snappy.parquet\r\n",
      "part-00015-e4c9e549-9fd3-4a97-b8b1-2cc71872198f-c000.snappy.parquet\r\n",
      "part-00016-e4c9e549-9fd3-4a97-b8b1-2cc71872198f-c000.snappy.parquet\r\n",
      "part-00017-e4c9e549-9fd3-4a97-b8b1-2cc71872198f-c000.snappy.parquet\r\n",
      "part-00018-e4c9e549-9fd3-4a97-b8b1-2cc71872198f-c000.snappy.parquet\r\n",
      "part-00019-e4c9e549-9fd3-4a97-b8b1-2cc71872198f-c000.snappy.parquet\r\n",
      "part-00020-e4c9e549-9fd3-4a97-b8b1-2cc71872198f-c000.snappy.parquet\r\n",
      "part-00021-e4c9e549-9fd3-4a97-b8b1-2cc71872198f-c000.snappy.parquet\r\n",
      "part-00022-e4c9e549-9fd3-4a97-b8b1-2cc71872198f-c000.snappy.parquet\r\n",
      "part-00023-e4c9e549-9fd3-4a97-b8b1-2cc71872198f-c000.snappy.parquet\r\n"
     ]
    }
   ],
   "source": [
    "!ls 'fhvhv/2021/01/'\n",
    "# 24 partition files were created!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c9c0abd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0M\tfhvhv/2021/01/part-00000-e4c9e549-9fd3-4a97-b8b1-2cc71872198f-c000.snappy.parquet\r\n"
     ]
    }
   ],
   "source": [
    "!du -sh 'fhvhv/2021/01/part-00000-e4c9e549-9fd3-4a97-b8b1-2cc71872198f-c000.snappy.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "716dfbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('fhvhv/2021/01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7d9cd69b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hvfhs_license_num: string (nullable = true)\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropoff_datetime: timestamp (nullable = true)\n",
      " |-- PULocationID: integer (nullable = true)\n",
      " |-- DOLocationID: integer (nullable = true)\n",
      " |-- SR_Flag: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5ef2d1c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+------------+------------+\n",
      "|    pickup_datetime|   dropoff_datetime|PULocationID|DOLocationID|\n",
      "+-------------------+-------------------+------------+------------+\n",
      "|2021-01-04 09:56:14|2021-01-04 10:18:54|         166|         234|\n",
      "|2021-01-07 01:58:26|2021-01-07 02:04:45|          35|          77|\n",
      "|2021-01-06 15:13:09|2021-01-06 15:28:36|         169|          69|\n",
      "|2021-01-03 16:19:52|2021-01-03 16:27:13|         170|         161|\n",
      "|2021-01-01 00:33:20|2021-01-01 00:46:08|         168|          42|\n",
      "|2021-01-05 23:33:36|2021-01-05 23:47:15|          35|         222|\n",
      "|2021-01-06 08:53:18|2021-01-06 09:06:09|          74|         151|\n",
      "|2021-01-06 09:16:53|2021-01-06 10:18:41|         168|         132|\n",
      "|2021-01-02 10:51:13|2021-01-02 10:58:34|          47|          18|\n",
      "|2021-01-02 21:54:41|2021-01-02 22:09:47|         239|         141|\n",
      "|2021-01-05 12:07:31|2021-01-05 12:17:42|         168|          42|\n",
      "|2021-01-01 19:49:13|2021-01-01 20:07:12|          72|          61|\n",
      "|2021-01-04 21:55:46|2021-01-04 22:03:01|          18|          18|\n",
      "|2021-01-06 05:20:34|2021-01-06 05:24:46|         174|         174|\n",
      "|2021-01-01 22:39:40|2021-01-01 22:55:17|         255|         228|\n",
      "|2021-01-03 13:40:42|2021-01-03 13:45:29|          76|          76|\n",
      "|2021-01-05 09:04:13|2021-01-05 09:14:50|         236|         262|\n",
      "|2021-01-06 19:28:07|2021-01-06 19:57:40|         155|         218|\n",
      "|2021-01-01 13:01:37|2021-01-01 13:14:09|          78|          69|\n",
      "|2021-01-06 12:55:18|2021-01-06 13:00:51|          21|          22|\n",
      "+-------------------+-------------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('pickup_datetime', 'dropoff_datetime', 'PULocationID', 'DOLocationID').filter(df.hvfhs_license_num=='HV0003').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9b4ea9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Operations\n",
    "# 1. Transformation - lazy execitopm. select, filter, map, joins, group by\n",
    "# 2. Actions - eager execution(executed immediately) . E.g show, count, take, head, write "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b3df05a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(pickup_datetime=datetime.datetime(2021, 1, 4, 9, 56, 14), dropoff_datetime=datetime.datetime(2021, 1, 4, 10, 18, 54), PULocationID=166, DOLocationID=234),\n",
       " Row(pickup_datetime=datetime.datetime(2021, 1, 7, 1, 58, 26), dropoff_datetime=datetime.datetime(2021, 1, 7, 2, 4, 45), PULocationID=35, DOLocationID=77),\n",
       " Row(pickup_datetime=datetime.datetime(2021, 1, 6, 15, 13, 9), dropoff_datetime=datetime.datetime(2021, 1, 6, 15, 28, 36), PULocationID=169, DOLocationID=69),\n",
       " Row(pickup_datetime=datetime.datetime(2021, 1, 3, 16, 19, 52), dropoff_datetime=datetime.datetime(2021, 1, 3, 16, 27, 13), PULocationID=170, DOLocationID=161),\n",
       " Row(pickup_datetime=datetime.datetime(2021, 1, 1, 0, 33, 20), dropoff_datetime=datetime.datetime(2021, 1, 1, 0, 46, 8), PULocationID=168, DOLocationID=42),\n",
       " Row(pickup_datetime=datetime.datetime(2021, 1, 5, 23, 33, 36), dropoff_datetime=datetime.datetime(2021, 1, 5, 23, 47, 15), PULocationID=35, DOLocationID=222),\n",
       " Row(pickup_datetime=datetime.datetime(2021, 1, 6, 8, 53, 18), dropoff_datetime=datetime.datetime(2021, 1, 6, 9, 6, 9), PULocationID=74, DOLocationID=151),\n",
       " Row(pickup_datetime=datetime.datetime(2021, 1, 6, 9, 16, 53), dropoff_datetime=datetime.datetime(2021, 1, 6, 10, 18, 41), PULocationID=168, DOLocationID=132),\n",
       " Row(pickup_datetime=datetime.datetime(2021, 1, 2, 10, 51, 13), dropoff_datetime=datetime.datetime(2021, 1, 2, 10, 58, 34), PULocationID=47, DOLocationID=18),\n",
       " Row(pickup_datetime=datetime.datetime(2021, 1, 2, 21, 54, 41), dropoff_datetime=datetime.datetime(2021, 1, 2, 22, 9, 47), PULocationID=239, DOLocationID=141)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('pickup_datetime', 'dropoff_datetime', 'PULocationID', 'DOLocationID').filter(df.hvfhs_license_num=='HV0003').head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5240202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spark sql functions\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7552ca88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+------------+------------+\n",
      "|pickup_date|dropoff_date|PULocationID|DOLocationID|\n",
      "+-----------+------------+------------+------------+\n",
      "| 2021-01-04|  2021-01-04|         166|         234|\n",
      "| 2021-01-07|  2021-01-07|          35|          77|\n",
      "| 2021-01-04|  2021-01-04|         232|         161|\n",
      "| 2021-01-04|  2021-01-04|         242|           3|\n",
      "| 2021-01-05|  2021-01-05|         130|         260|\n",
      "| 2021-01-01|  2021-01-01|          41|         133|\n",
      "| 2021-01-06|  2021-01-06|         169|          69|\n",
      "| 2021-01-03|  2021-01-03|         170|         161|\n",
      "| 2021-01-01|  2021-01-01|         168|          42|\n",
      "| 2021-01-05|  2021-01-05|          35|         222|\n",
      "| 2021-01-06|  2021-01-06|          74|         151|\n",
      "| 2021-01-02|  2021-01-02|          76|          76|\n",
      "| 2021-01-06|  2021-01-06|         168|         132|\n",
      "| 2021-01-03|  2021-01-03|         233|          95|\n",
      "| 2021-01-01|  2021-01-01|          68|         265|\n",
      "| 2021-01-02|  2021-01-02|          47|          18|\n",
      "| 2021-01-04|  2021-01-04|          61|          17|\n",
      "| 2021-01-04|  2021-01-04|          89|          91|\n",
      "| 2021-01-05|  2021-01-05|         231|         265|\n",
      "| 2021-01-02|  2021-01-02|         239|         141|\n",
      "+-----------+------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .withColumn('dropoff_date', F.to_date(df.dropoff_datetime)) \\\n",
    "    .select('pickup_date', 'dropoff_date', 'PULocationID', 'DOLocationID') \\\n",
    "    .show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8dc68e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crazy_stuff(base_num):\n",
    "    num = int(base_num[1:])\n",
    "    if num % 7 == 0:\n",
    "        return f's/{num:03x}'\n",
    "    elif num % 3 == 0:\n",
    "        return f'a/{num:03x}'\n",
    "    else:\n",
    "        return f'e/{num:03x}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "22b5d784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e/b45'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crazy_stuff('B02885')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8a6c7d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "crazy_stuff_udf = F.udf(crazy_stuff, returnType=StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "910362dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------+------------+------------+------------+\n",
      "|base_id|pickup_date|dropoff_date|PULocationID|DOLocationID|\n",
      "+-------+-----------+------------+------------+------------+\n",
      "|  e/b30| 2021-01-04|  2021-01-04|         166|         234|\n",
      "|  e/b42| 2021-01-07|  2021-01-07|          35|          77|\n",
      "|  s/af0| 2021-01-04|  2021-01-04|         232|         161|\n",
      "|  e/9ce| 2021-01-04|  2021-01-04|         242|           3|\n",
      "|  e/9ce| 2021-01-05|  2021-01-05|         130|         260|\n",
      "|  e/9ce| 2021-01-01|  2021-01-01|          41|         133|\n",
      "|  e/b3f| 2021-01-06|  2021-01-06|         169|          69|\n",
      "|  e/b42| 2021-01-03|  2021-01-03|         170|         161|\n",
      "|  e/b3e| 2021-01-01|  2021-01-01|         168|          42|\n",
      "|  s/acd| 2021-01-05|  2021-01-05|          35|         222|\n",
      "|  s/acd| 2021-01-06|  2021-01-06|          74|         151|\n",
      "|  e/9ce| 2021-01-02|  2021-01-02|          76|          76|\n",
      "|  s/b44| 2021-01-06|  2021-01-06|         168|         132|\n",
      "|  e/9ce| 2021-01-03|  2021-01-03|         233|          95|\n",
      "|  e/9ce| 2021-01-01|  2021-01-01|          68|         265|\n",
      "|  e/b30| 2021-01-02|  2021-01-02|          47|          18|\n",
      "|  e/9ce| 2021-01-04|  2021-01-04|          61|          17|\n",
      "|  e/9ce| 2021-01-04|  2021-01-04|          89|          91|\n",
      "|  e/9ce| 2021-01-05|  2021-01-05|         231|         265|\n",
      "|  s/b3d| 2021-01-02|  2021-01-02|         239|         141|\n",
      "+-------+-----------+------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/thamizh/apps/spark-3.0.3-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/daemon.py\", line 186, in manager\n",
      "  File \"/home/thamizh/apps/spark-3.0.3-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/daemon.py\", line 74, in worker\n",
      "  File \"/home/thamizh/apps/spark-3.0.3-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/worker.py\", line 642, in main\n",
      "    if read_int(infile) == SpecialLengths.END_OF_STREAM:\n",
      "  File \"/home/thamizh/apps/spark-3.0.3-bin-hadoop3.2/python/lib/pyspark.zip/pyspark/serializers.py\", line 595, in read_int\n",
      "    raise EOFError\n",
      "EOFError\n"
     ]
    }
   ],
   "source": [
    "df \\\n",
    "    .withColumn('pickup_date', F.to_date(df.pickup_datetime)) \\\n",
    "    .withColumn('dropoff_date', F.to_date(df.dropoff_datetime)) \\\n",
    "    .withColumn('base_id', crazy_stuff_udf(df.dispatching_base_num)) \\\n",
    "    .select('base_id','pickup_date', 'dropoff_date', 'PULocationID', 'DOLocationID') \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f1f706",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
